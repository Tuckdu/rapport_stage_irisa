\bibliographystyle{plain}
\addcontentsline{toc}{chapter}{Bibliographie}
\begin{thebibliography}{99}

	\bibitem{irisa}
	  Site de l'IRISA - Présentation du laboratoire\\
    \link{https://www.irisa.fr/fr/page/recherche-innovation-sciences-technologies-du-numerique}
      
  \bibitem{percept}
	  Site de l'IRISA - Présentation de l'équipe PERCEPT\\
    \link{https://www.irisa.fr/fr/equipes/percept}

  \bibitem{gaze}
    \emph{Art, Aesthetics, and the brain}, 2015\\
    JP. Huston, M. Nadal, F. Mora, LF. Agnati, CJ. Cela-Conde
  
  \bibitem{how_see_art}
    \emph{How do we see art: an eye-tracker study}, 2011\\
    RQ. Quiroga, C. Pedreira

  \bibitem{visual_exploration}
    \emph{Visual exploration patterns of human figures in action: an eye-tracker study with art paintings}, 2015\\
    S. Vilani, F. Morganti, P. Cipresso, S. Ruggi, G. Riva, G. Gilli

  \bibitem{van_gogh}
    \emph{Looking at paintings in the Vincent Van Gogh Museum: Eye movement patterns of children and adults}, 2017\\
    F. Walker, B. Bucker, NC. Anderson, D. Schreij, J. Theeuwes

  \bibitem{caravagio}
    \emph{Driven by Caravaggio through his painting an eye-tracking study}, 2016\\
    B. Balbi, F. Protti, R. Montanari

  \bibitem{saillance}
    \emph{Saillance physique et saillance cognitive}, 2004\\
    F. Landragin\\
    \link{https://doi.org/10.4000/corela.603}

  \bibitem{benchmark_MIT}
    \emph{MIT saliency benchmark}, 2015\\
    Z. Bylinskii, T. Judd, A. Borji, L. Itti, F. Durand, A. Oliva, et al.\\
    \link{http://saliency.mit.edu/}

  \bibitem{GBVS}
    \emph{Graph-based visual saliency}, 2007\\
    J. Harel, C. Koch, P.Perona

  \bibitem{RARE2012}
    \emph{Rare: A new bottom-up saliency model}, 2012\\
    N. Riche, M. Mancas, B. Gosselin, T. Dutoit

  \bibitem{AIM}
    \emph{Attention based on information maximization.} 2007\\
    N. Bruce, J. Tsotsos

  \bibitem{AWS}
    \emph{On the relationship between optical variability, visual saliency, and eye fixations: A computational approach.}, 2012\\
    A.Garcia-Diaz, V. Leboran, XR. Fdez-Vidal, XM. Pardo

  \bibitem{MLNET}
    \emph{A Deep Multi-Level Network for Saliency Prediction.}, 2016\\
    M. Cornia, L. Baraldi, G. Serra, C. Rita

  \bibitem{deepGazeII}
  \emph{DeepGaze II: Reading fixations from deep features trained on object recognition.}, 2016\\
  M.Kümerrer, TSA. Wallis, M. Bethge

  \bibitem{SALICON}
    \emph{Salicon: Reducing the semantic gap insaliency prediction by adapting deep neural networks}, 2015\\
    X. Huang, C. Shen, X. Boix, Q. Zhao

  \bibitem{SAM}
    \emph{Predicting human eye fixations viaan lstm-based saliency attentive model}, 2018\\
    M. Cornia, L. Barraldi, G. Serra, R. Gucchiara

  \bibitem{eaktalab}
    Projet "Eye-tracking and Comics" de Eakta Jain\\
    \link{https://jainlab.cise.ufl.edu/comics.html}

  \bibitem{kenburns}
    \emph{Predicting Moves-on-Stills for Comic Artusing Viewer Gaze Data}, 2015\\
    E. Jain, Y. Sheikh, J. Hodgins\\
    \link{https://jainlab.cise.ufl.edu/documents/motion-comics-cga2015.pdf}

  \bibitem{kenburns3D}
    \emph{3D Ken Burns Effect from a Single Image}, 2019\\
    S. Niklaus, L. Mai, J. Yang, F. Liu\\
    \link{https://arxiv.org/pdf/1909.05483.pdf}

  \bibitem{saccadicmodel}
    \emph{Saccadic model of eye movements for free-viewing condition}, 2015\\
    O. Le Meur, Z. Liu\\
    \link{https://www.sciencedirect.com/science/article/pii/S0042698915000504}

  \bibitem{segmentationcomics}
    \emph{Creating Segments and Effects on Comics by Clustering Gaze Data}, 2017\\
    I. Thirunarayanan, K. Khetarpal, S. Koppal, O. Le Meur, J. Shea, E. Jain\\
    \link{https://jainlab.cise.ufl.edu/documents/REQGazeComics\_preprint.pdf}

  \bibitem{neuraltalk2}
    Neuraltalk2 code\\
    A. Karpathy\\
    \link{https://github.com/karpathy/neuraltalk2}

\end{thebibliography}
